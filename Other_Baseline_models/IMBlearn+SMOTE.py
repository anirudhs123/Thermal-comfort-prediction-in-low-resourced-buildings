# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14boSphvuxVE_x8cI-sHxTgBZLHDbcPLI
"""

import pandas as pd
import numpy as np 
data_us=pd.read_csv('/content/drive/My Drive/Colab Notebooks/Thermal sensation prediction(Murata)/Medium_office.csv')
data_C=pd.read_csv('/content/drive/My Drive/Colab Notebooks/Thermal sensation prediction(Murata)/Ashrae_clean.csv')

data_C.drop(['Unnamed: 0'],axis=1,inplace=True)
data_C=data_C.drop_duplicates(['Age',	'Sex','Air velocity (m/s)',	'Air temperature (¡C)',	'Radiant temperature (¡C)',	'Relative humidity (%)',	'Clo',	'Met',	'Outdoor monthly air temperature (¡C)'])

data_us.drop(['Unnamed: 0'],axis=1,inplace=True)
data_us=data_us.drop_duplicates(['Age',	'Sex','Air velocity (m/s)',	'Air temperature (¡C)',	'Radiant temperature (¡C)',	'Relative humidity (%)',	'Clo',	'Met',	'Outdoor monthly air temperature (¡C)'])

data_us_C=data_us
data_us_B=data_us.drop(['Outdoor monthly air temperature (¡C)'],axis=1)
data_us_A=data_us_B.drop(['Age','Sex'],axis=1)

data_B=data_C.drop(['Outdoor monthly air temperature (¡C)'],axis=1)
data_A=data_B.drop(['Age','Sex'],axis=1)

def fun1(x):
  return(np.round(x,2))

cols=['Air velocity (m/s)','Air temperature (¡C)','Radiant temperature (¡C)','Relative humidity (%)']  
for col in cols:
  data_us_A[col]=data_us_A[col].apply(lambda x:fun1(x))
  data_us_B[col]=data_us_B[col].apply(lambda x:fun1(x))
  data_us_C[col]=data_us_C[col].apply(lambda x:fun1(x))

from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, cross_val_score
from sklearn.pipeline import make_pipeline
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import RandomUnderSampler

from sklearn.preprocessing import RobustScaler
import warnings
warnings.filterwarnings("ignore")

X_train=data_C.drop(['Thermal sensation'],axis=1)
y_train=data_C['Thermal sensation']
X_test=data_us_C.drop(['Thermal sensation'],axis=1)
y_test=data_us_C['Thermal sensation']

X_bal, y_bal = ADASYN(sampling_strategy='minority',random_state=0).fit_resample(X_train,y_train)

# Join X and y
X_bal = pd.DataFrame(X_bal,columns=X_train.columns)
y_bal = pd.DataFrame(y_bal,columns=['Thermal Sensation'])
balanced = X_bal.join(y_bal)

#Importing the metrics to compare the model performance
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score
from sklearn.metrics import matthews_corrcoef,confusion_matrix
#This functions trains the model and performs prediction and anlaysis of model  performance
def model_performance(model,X_test,y_test,model_name):
  y_pred=model.predict(X_test)
  acc=accuracy_score(y_test,y_pred)
  cm=confusion_matrix(y_test,y_pred)
  recall = np.diag(cm) / np.sum(cm, axis = 1)
  precision = np.diag(cm) / np.sum(cm, axis = 0)
  precs=np.mean(recall)
  recall=np.mean(precision)
  f1=(2*precs*recall)/(precs+recall)
  coeff=matthews_corrcoef(y_test,y_pred)
  print('Accuracy of {} is: {}'.format(model_name,acc))
  print('F1_Score of {} is: {}'.format(model_name,f1))
  print('Precsion of {} is: {}'.format(model_name,precs))
  print('Recall of {} is: {}'.format(model_name,recall))
  print('Confusion matrix of {} is:'.format(model_name))
  print(cm)

from sklearn.ensemble import RandomForestClassifier
RF_model=RandomForestClassifier(n_estimators=200,class_weight='balanced_subsample',max_depth=12)

model=RF_model
model.fit(X_bal,y_bal)
model_performance(model,X_test,y_test,'RF_model')





from imblearn.ensemble import BalancedRandomForestClassifier
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline

# transform the dataset
oversample = SMOTE()
X_1, y_1 = oversample.fit_resample(X_train, y_train)

from collections import Counter
counter = Counter(y_train)
print(counter)

over = SMOTE(sampling_strategy={0:18000,1:18000,2:18000,3:18000,4:18000})
under = RandomUnderSampler(sampling_strategy={0:10000,1:10000,2:10000,3:10000,4:10000})
steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)
# transform the dataset
X, y = pipeline.fit_resample(X_train, y_train)

RF_model=RandomForestClassifier(n_estimators=100,class_weight='balanced_subsample',max_depth=12)
model=RF_model
model.fit(X,y)
model_performance(model,X_test,y_test,'RF_model')

from keras.models import Sequential
from keras.layers import Dense,Dropout,ReLU
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from keras.utils import to_categorical
from keras.layers import Embedding,Conv1D,LSTM,Input,TimeDistributed,SpatialDropout1D,Flatten,Dropout
from keras.models import Model
from keras.callbacks import ModelCheckpoint
from sklearn.preprocessing import MinMaxScaler
def build_model_LSTM(X_train,y_train):
  y_train=np.asarray(y_train ,dtype=int)
  y_train=to_categorical(y_train,num_classes=5)
  model=Sequential()
  model.add(Embedding(101,256,input_length=len(X_train[0]),))
  model.add(Conv1D(filters=128,kernel_size=5,padding='same'))
  model.add(SpatialDropout1D(0.1))
  model.add(LSTM(256,return_sequences=True))
  model.add(LSTM(256,return_sequences=True))
  model.add(Flatten())
  model.add(Dense(64,activation='relu'))
  model.add(Dropout(0.1))
  model.add(Dense(16,activation='relu'))
  model.add(Dropout(0.1))
  model.add(Dense(5,activation='softmax'))
  model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001,beta_1=0.99,beta_2=0.999),metrics=['accuracy'])
  es=EarlyStopping(monitor='val_loss',restore_best_weights=True)
  model.fit(X_train,y_train,epochs=20,validation_split=0.2,batch_size=128)
  model.summary()
  return(model)

#Importing the metrics to compare the model performance
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score
from sklearn.metrics import matthews_corrcoef,confusion_matrix
#This functions trains the model and performs prediction and anlaysis of model  performance
def model_performance_MLP(model,X_test,y_test,model_name):
  y_pred=model.predict(X_test)
  y_preds=[]
  for i in range(len(y_pred)):
    y_preds.append(np.argmax(y_pred[i]))

  y_pred=y_preds
  acc=accuracy_score(y_test,y_pred)
  cm=confusion_matrix(y_test,y_pred)
  recall = np.diag(cm) / np.sum(cm, axis = 1)
  precision = np.diag(cm) / np.sum(cm, axis = 0)
  precs=np.mean(recall)
  recall=np.mean(precision)
  f1=(2*precs*recall)/(precs+recall)
  coeff=matthews_corrcoef(y_test,y_pred)
  print('Accuracy of {} is: {}'.format(model_name,acc))
  print('F1_Score of {} is: {}'.format(model_name,f1))
  print('Precsion of {} is: {}'.format(model_name,precs))
  print('Recall of {} is: {}'.format(model_name,recall))
  print('Confusion matrix of {} is:'.format(model_name))
  print(cm)









